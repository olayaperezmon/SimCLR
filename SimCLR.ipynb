{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SimCLR\n",
    "PyTorch implementation of SimCLR: A Simple Framework for Contrastive Learning of Visual Representations by T. Chen et al. With support for the LARS (Layer-wise Adaptive Rate Scaling) optimizer and global batch norm.\n",
    "\n",
    "[Link to paper](https://arxiv.org/pdf/2002.05709.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 17 10:26:17 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN Xp            Off  | 00000000:17:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8     8W / 250W |   4189MiB / 12196MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN Xp            Off  | 00000000:65:00.0 Off |                  N/A |\n",
      "| 23%   36C    P8     9W / 250W |    939MiB / 12194MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi \n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyyaml in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install  pyyaml --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: simCLR in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: torchvision in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from simCLR) (0.12.0)\n",
      "Requirement already satisfied: pyyaml in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from simCLR) (6.0)\n",
      "Requirement already satisfied: torch in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from simCLR) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from torch->simCLR) (4.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from torchvision->simCLR) (8.4.0)\n",
      "Requirement already satisfied: requests in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from torchvision->simCLR) (2.26.0)\n",
      "Requirement already satisfied: numpy in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from torchvision->simCLR) (1.20.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from requests->torchvision->simCLR) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from requests->torchvision->simCLR) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from requests->torchvision->simCLR) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /media/nas/olayap/anaconda3/lib/python3.9/site-packages (from requests->torchvision->simCLR) (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install simCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1:\n",
    "## SimCLR pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np  \n",
    "import argparse\n",
    "\n",
    "apex = False\n",
    "try:\n",
    "    from apex import amp\n",
    "    apex = True\n",
    "except ImportError:\n",
    "    print(\n",
    "        \"Install the apex package from https://www.github.com/nvidia/apex to use fp16 for training\"\n",
    "    )\n",
    "\n",
    "\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import get_resnet, NT_Xent\n",
    "from simclr.modules.transformations import TransformsSimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load arguments from `config/config.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import argparse\n",
    "from utils import yaml_config_hook\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args([])\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'dataparallel': 0,\n",
      " 'dataset': '',\n",
      " 'dataset_dir': './data',\n",
      " 'epoch_num': 10,\n",
      " 'epochs': 10,\n",
      " 'gpus': ['0 1'],\n",
      " 'image_size': 64,\n",
      " 'logistic_batch_size': 256,\n",
      " 'logistic_epochs': 500,\n",
      " 'model_path': 'model18_simclr.pt',\n",
      " 'nodes': 1,\n",
      " 'nr': 1,\n",
      " 'optimizer': 'Adam',\n",
      " 'pretrain': True,\n",
      " 'projection_dim': 64,\n",
      " 'reload': False,\n",
      " 'resnet': 'resnet18',\n",
      " 'seed': 9,\n",
      " 'start_epoch': 0,\n",
      " 'temperature': 0.5,\n",
      " 'weight_decay': 1e-06,\n",
      " 'workers': 12}\n"
     ]
    }
   ],
   "source": [
    "### override any configuration parameters here, e.g. to adjust for use on GPUs on the Colab platform:\n",
    "args.batch_size = 64\n",
    "args.resnet = \"resnet18\"\n",
    "pprint(vars(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset into train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Sample  roi_number        OriginalClass  \\\n",
      "0        IFCB1_2006_158_000036           1                  mix   \n",
      "1        IFCB1_2006_158_000036           2  Tontonia_gracillima   \n",
      "2        IFCB1_2006_158_000036           3                  mix   \n",
      "3        IFCB1_2006_158_000036           4                  mix   \n",
      "4        IFCB1_2006_158_000036           5                  mix   \n",
      "...                        ...         ...                  ...   \n",
      "3457814  IFCB5_2014_353_205141        6850       Leptocylindrus   \n",
      "3457815  IFCB5_2014_353_205141        6852                  mix   \n",
      "3457816  IFCB5_2014_353_205141        6855                  mix   \n",
      "3457817  IFCB5_2014_353_205141        6856                  mix   \n",
      "3457818  IFCB5_2014_353_205141        6857                  mix   \n",
      "\n",
      "              AutoClass FunctionalGroup  year  \n",
      "0                   mix      Flagellate  2006  \n",
      "1           ciliate_mix         Ciliate  2006  \n",
      "2                   mix      Flagellate  2006  \n",
      "3                   mix      Flagellate  2006  \n",
      "4                   mix      Flagellate  2006  \n",
      "...                 ...             ...   ...  \n",
      "3457814  Leptocylindrus          Diatom  2014  \n",
      "3457815             mix      Flagellate  2014  \n",
      "3457816             mix      Flagellate  2014  \n",
      "3457817             mix      Flagellate  2014  \n",
      "3457818             mix      Flagellate  2014  \n",
      "\n",
      "[3457819 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "if not os.path.isfile('IFCB.csv.zip'):\n",
    "    print(\"CSV data do not exist. Downloading...\")\n",
    "    !wget -O IFCB.csv.zip \"https://unioviedo-my.sharepoint.com/:u:/g/personal/gonzalezgpablo_uniovi_es/EfsVLhFsYJpPjO0KZlpWUq0BU6LaqJ989Re4XzatS9aG4Q?download=1\"\n",
    "\n",
    "data = pd.read_csv('IFCB.csv.zip',compression='infer', header=0,sep=',',quotechar='\"')\n",
    "\n",
    "#Compute sample and year information\n",
    "data['year'] = data['Sample'].str[6:10].astype(str) #Compute the year\n",
    "samples=data.groupby('Sample').first()\n",
    "samples = samples[[\"year\"]]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar\n",
    "from tqdm import tqdm\n",
    "from shutil import copyfile\n",
    "import numpy as np\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "classcolumn = \"AutoClass\" #AutoClass means 51 classes\n",
    "yearstraining = ['2006','2007'] #Years to consider as training\n",
    "yearstest = ['2008'] #Years to consider as test\n",
    "\n",
    "samplestraining = list(samples[samples['year'].isin(yearstraining)].index) #Samples to consider for training\n",
    "samplestest = list(samples[samples['year'].isin(yearstest)].index) #Samples to consider for testing\n",
    "\n",
    "classes=np.unique(data[classcolumn])\n",
    "classes.sort()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from h5ifcbdataset import H5IFCBDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "hdf5_files_path = \"/media/nas/olayap/env_olaya/TFM/IFBC_HDF5_olaya/output/\"\n",
    "\n",
    "#files to load\n",
    "filestraining = [hdf5_files_path+s+'.hdf5' for s in samplestraining]\n",
    "filestest = [hdf5_files_path+s+'.hdf5' for s in samplestest]\n",
    "\n",
    "train_dset = H5IFCBDataset(filestraining,classes,classattribute=classcolumn, verbose=1,trainingset=False,transform=TransformsSimCLR(size=args.image_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctg = 0.2\n",
    "percentage = round(pctg*len(train_dset))\n",
    "train_dset_pctg_label, train_dset_pctg_unlabel = torch.utils.data.random_split(train_dset, [percentage, len(train_dset)-percentage], generator=torch.Generator().manual_seed(0))\n",
    "train_loader_unlabel = DataLoader(train_dset_pctg_unlabel,batch_size=args.batch_size,num_workers=args.workers,shuffle=True,pin_memory=True,drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 100\n",
    "args.model_path = \"model18_simclr_20_pr.pt\"\n",
    "args.batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the SimCLR model, optimizer and learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from simclr.modules import LARS\n",
    "\n",
    "# initialize ResNet\n",
    "encoder = get_resnet(args.resnet, pretrained=False)\n",
    "n_features = encoder.fc.in_features  \n",
    "\n",
    "\n",
    "# initialize model\n",
    "model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "model = model.to(device)\n",
    "\n",
    "# optimizer / loss\n",
    "scheduler = None\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the criterion (NT-Xent loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NT_Xent(args.batch_size, args.temperature, world_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, train_loader, model, criterion, optimizer): \n",
    "    loss_epoch = 0\n",
    "    for step, ((x_i, x_j),_, _)  in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.cuda(non_blocking=True)\n",
    "        x_j = x_j.cuda(non_blocking=True)\n",
    "    \n",
    "        # positive pair, with encoding\n",
    "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "\n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % 100 == 0:\n",
    "            print(f\"Step [{step}/{len(train_loader)}]\\t Loss: {loss.item()}\")\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        args.global_step += 1\n",
    "    return loss_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "\n",
    "args.global_step = 0\n",
    "args.current_epoch = 0\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    lr = optimizer.param_groups[0][\"lr\"]\n",
    "    loss_epoch = train(args, train_loader_unlabel, model, criterion, optimizer) \n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # save every 10 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        torch.save(model.state_dict(), args.model_path)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{args.epochs}]\\t Loss: {loss_epoch / len(train_loader_unlabel)}\\t lr: {round(lr, 5)}\"\n",
    "    )\n",
    "    args.current_epoch += 1\n",
    "\n",
    "# end training\n",
    "torch.save(model.state_dict(), args.model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2:\n",
    "## Linear evaluation using logistic regression, using weights from frozen, pre-trained SimCLR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_features, n_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "\n",
    "        self.model = nn.Linear(n_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, loader, simclr_model, model, criterion, optimizer):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.train()\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        # if step % 100 == 0:\n",
    "        #     print(\n",
    "        #         f\"Step [{step}/{len(loader)}]\\t Loss: {loss.item()}\\t Accuracy: {acc}\"\n",
    "        #     )\n",
    "\n",
    "    return loss_epoch, accuracy_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as nnf\n",
    "\n",
    "def test(args, loader, simclr_model, model, criterion, optimizer, percentage, results_save_path):\n",
    "    loss_epoch = 0\n",
    "    accuracy_epoch = 0\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "\n",
    "    for step, (x, y) in enumerate(loader):\n",
    "        model.zero_grad()\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "\n",
    "        predicted = output.argmax(1)\n",
    "        acc = (predicted == y).sum().item() / y.size(0)\n",
    "        accuracy_epoch += acc\n",
    "        \n",
    "        prob = nnf.softmax(output, dim=1)\n",
    "        y_probs.extend(prob.cpu().detach().numpy())\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "        loss_epoch += loss.item()\n",
    "        \n",
    "    np.savetxt(\"{}/{}_true.csv\".format(results_save_path,round(percentage*100)),y_true,fmt='%d')\n",
    "    np.savetxt(\"{}/{}_pred.csv\".format(results_save_path,round(percentage*100)),y_pred,fmt='%d')\n",
    "    np.savetxt(\"{}/{}_probs.csv\".format(results_save_path,round(percentage*100)), y_probs, delimiter=\",\",fmt='%f')\n",
    "\n",
    "    return loss_epoch, accuracy_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from utils import yaml_config_hook\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"SimCLR\")\n",
    "config = yaml_config_hook(\"./config/config.yaml\")\n",
    "for k, v in config.items():\n",
    "    parser.add_argument(f\"--{k}\", default=v, type=type(v))\n",
    "\n",
    "args = parser.parse_args([])\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset into train/test dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vuelvo a cargar el trainset porque sino se entrena la red con las transformaciones de data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading samples: 100%|██████████| 164/164 [07:35<00:00,  2.78s/it]\n"
     ]
    }
   ],
   "source": [
    "from trans_2 import TransformsSimCLR2\n",
    "train_dset_ = H5IFCBDataset(filestraining,classes,classattribute=classcolumn, verbose=1,trainingset=False,transform=TransformsSimCLR2(size=args.image_size))\n",
    "pctg = 0.2\n",
    "percentage = round(pctg*len(train_dset_))\n",
    "train_dset_pctg_label, _ = torch.utils.data.random_split(train_dset_, [percentage, len(train_dset_)-percentage], generator=torch.Generator().manual_seed(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading samples: 100%|██████████| 122/122 [08:49<00:00,  4.34s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dset = H5IFCBDataset(filestest,classes,classattribute=classcolumn, verbose=1,trainingset=False,transform=TransformsSimCLR2(size=args.image_size)) #.test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader_label = torch.utils.data.DataLoader(\n",
    "    train_dset_pctg_label,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dset,\n",
    "    batch_size=args.logistic_batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=args.workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet encoder / SimCLR and load model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = get_resnet(args.resnet, pretrained=False) # don't load a pre-trained model from PyTorch repo\n",
    "n_features = encoder.fc.in_features  # get dimensions of fc layer\n",
    "\n",
    "# load pre-trained model from checkpoint\n",
    "simclr_model = SimCLR(encoder, args.projection_dim, n_features)\n",
    "\n",
    "simclr_model.load_state_dict(torch.load(\"model18_simclr_20.pt\")) #, map_location=device.type)\n",
    "simclr_model = simclr_model.to(device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic Regression\n",
    "n_classes = len(classes) \n",
    "model = LogisticRegression(simclr_model.n_features, n_classes)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to map all input data $X$ to their latent representations $h$ that are used in linear evaluation (they only have to be computed once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loader, simclr_model, device):\n",
    "    feature_vector = []\n",
    "    labels_vector = []\n",
    "    for step, (x, y, _) in enumerate(loader):\n",
    "        \n",
    "        x = x[0].to(device)\n",
    "\n",
    "        # get encoding\n",
    "        with torch.no_grad():\n",
    "            h, _, z, _ = simclr_model(x, x)\n",
    "\n",
    "        h = h.detach()\n",
    "\n",
    "        feature_vector.extend(h.cpu().detach().numpy())\n",
    "        labels_vector.extend(y.numpy())\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step [{step}/{len(loader)}]\\t Computing features...\")\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    labels_vector = np.array(labels_vector)\n",
    "    print(\"Features shape {}\".format(feature_vector.shape))\n",
    "    return feature_vector, labels_vector\n",
    "\n",
    "\n",
    "def get_features(context_model, train_loader, test_loader, device):\n",
    "    train_X, train_y = inference(train_loader, context_model, device)\n",
    "    test_X, test_y = inference(test_loader, context_model, device)\n",
    "    return train_X, train_y, test_X, test_y\n",
    "\n",
    "\n",
    "def create_data_loaders_from_arrays(X_train, y_train, X_test, y_test, batch_size):\n",
    "    train = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_train), torch.from_numpy(y_train)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "\n",
    "    test = torch.utils.data.TensorDataset(\n",
    "        torch.from_numpy(X_test), torch.from_numpy(y_test)\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test, batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Creating features from pre-trained context model ###\n",
      "Step [0/315]\t Computing features...\n",
      "Step [20/315]\t Computing features...\n",
      "Step [40/315]\t Computing features...\n",
      "Step [60/315]\t Computing features...\n",
      "Step [80/315]\t Computing features...\n",
      "Step [100/315]\t Computing features...\n",
      "Step [120/315]\t Computing features...\n",
      "Step [140/315]\t Computing features...\n",
      "Step [160/315]\t Computing features...\n",
      "Step [180/315]\t Computing features...\n",
      "Step [200/315]\t Computing features...\n",
      "Step [220/315]\t Computing features...\n",
      "Step [240/315]\t Computing features...\n",
      "Step [260/315]\t Computing features...\n",
      "Step [280/315]\t Computing features...\n",
      "Step [300/315]\t Computing features...\n",
      "Features shape (80640, 512)\n",
      "Step [0/1669]\t Computing features...\n",
      "Step [20/1669]\t Computing features...\n",
      "Step [40/1669]\t Computing features...\n",
      "Step [60/1669]\t Computing features...\n",
      "Step [80/1669]\t Computing features...\n",
      "Step [100/1669]\t Computing features...\n",
      "Step [120/1669]\t Computing features...\n",
      "Step [140/1669]\t Computing features...\n",
      "Step [160/1669]\t Computing features...\n",
      "Step [180/1669]\t Computing features...\n",
      "Step [200/1669]\t Computing features...\n",
      "Step [220/1669]\t Computing features...\n",
      "Step [240/1669]\t Computing features...\n",
      "Step [260/1669]\t Computing features...\n",
      "Step [280/1669]\t Computing features...\n",
      "Step [300/1669]\t Computing features...\n",
      "Step [320/1669]\t Computing features...\n",
      "Step [340/1669]\t Computing features...\n",
      "Step [360/1669]\t Computing features...\n",
      "Step [380/1669]\t Computing features...\n",
      "Step [400/1669]\t Computing features...\n",
      "Step [420/1669]\t Computing features...\n",
      "Step [440/1669]\t Computing features...\n",
      "Step [460/1669]\t Computing features...\n",
      "Step [480/1669]\t Computing features...\n",
      "Step [500/1669]\t Computing features...\n",
      "Step [520/1669]\t Computing features...\n",
      "Step [540/1669]\t Computing features...\n",
      "Step [560/1669]\t Computing features...\n",
      "Step [580/1669]\t Computing features...\n",
      "Step [600/1669]\t Computing features...\n",
      "Step [620/1669]\t Computing features...\n",
      "Step [640/1669]\t Computing features...\n",
      "Step [660/1669]\t Computing features...\n",
      "Step [680/1669]\t Computing features...\n",
      "Step [700/1669]\t Computing features...\n",
      "Step [720/1669]\t Computing features...\n",
      "Step [740/1669]\t Computing features...\n",
      "Step [760/1669]\t Computing features...\n",
      "Step [780/1669]\t Computing features...\n",
      "Step [800/1669]\t Computing features...\n",
      "Step [820/1669]\t Computing features...\n",
      "Step [840/1669]\t Computing features...\n",
      "Step [860/1669]\t Computing features...\n",
      "Step [880/1669]\t Computing features...\n",
      "Step [900/1669]\t Computing features...\n",
      "Step [920/1669]\t Computing features...\n",
      "Step [940/1669]\t Computing features...\n",
      "Step [960/1669]\t Computing features...\n",
      "Step [980/1669]\t Computing features...\n",
      "Step [1000/1669]\t Computing features...\n",
      "Step [1020/1669]\t Computing features...\n",
      "Step [1040/1669]\t Computing features...\n",
      "Step [1060/1669]\t Computing features...\n",
      "Step [1080/1669]\t Computing features...\n",
      "Step [1100/1669]\t Computing features...\n",
      "Step [1120/1669]\t Computing features...\n",
      "Step [1140/1669]\t Computing features...\n",
      "Step [1160/1669]\t Computing features...\n",
      "Step [1180/1669]\t Computing features...\n",
      "Step [1200/1669]\t Computing features...\n",
      "Step [1220/1669]\t Computing features...\n",
      "Step [1240/1669]\t Computing features...\n",
      "Step [1260/1669]\t Computing features...\n",
      "Step [1280/1669]\t Computing features...\n",
      "Step [1300/1669]\t Computing features...\n",
      "Step [1320/1669]\t Computing features...\n",
      "Step [1340/1669]\t Computing features...\n",
      "Step [1360/1669]\t Computing features...\n",
      "Step [1380/1669]\t Computing features...\n",
      "Step [1400/1669]\t Computing features...\n",
      "Step [1420/1669]\t Computing features...\n",
      "Step [1440/1669]\t Computing features...\n",
      "Step [1460/1669]\t Computing features...\n",
      "Step [1480/1669]\t Computing features...\n",
      "Step [1500/1669]\t Computing features...\n",
      "Step [1520/1669]\t Computing features...\n",
      "Step [1540/1669]\t Computing features...\n",
      "Step [1560/1669]\t Computing features...\n",
      "Step [1580/1669]\t Computing features...\n",
      "Step [1600/1669]\t Computing features...\n",
      "Step [1620/1669]\t Computing features...\n",
      "Step [1640/1669]\t Computing features...\n",
      "Step [1660/1669]\t Computing features...\n",
      "Features shape (427264, 512)\n"
     ]
    }
   ],
   "source": [
    "print(\"### Creating features from pre-trained context model ###\")\n",
    "(train_X, train_y, test_X, test_y) = get_features(\n",
    "    simclr_model, train_loader_label, test_loader, device\n",
    ")\n",
    "\n",
    "arr_train_loader, arr_test_loader = create_data_loaders_from_arrays(\n",
    "    train_X, train_y, test_X, test_y, args.logistic_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.logistic_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/500]\t Loss: 0.2674724187642809\t Accuracy: 0.9021825396825397\n",
      "Epoch [10/500]\t Loss: 0.2657891698772945\t Accuracy: 0.9026785714285714\n",
      "Epoch [20/500]\t Loss: 0.2642168392264654\t Accuracy: 0.9031125992063492\n",
      "Epoch [30/500]\t Loss: 0.2627426349454456\t Accuracy: 0.9038938492063492\n",
      "Epoch [40/500]\t Loss: 0.2613558163245519\t Accuracy: 0.9042286706349206\n",
      "Epoch [50/500]\t Loss: 0.2600473162200716\t Accuracy: 0.9045882936507936\n",
      "Epoch [60/500]\t Loss: 0.25880938224376193\t Accuracy: 0.9048983134920635\n",
      "Epoch [70/500]\t Loss: 0.25763536554480354\t Accuracy: 0.9052083333333333\n",
      "Epoch [80/500]\t Loss: 0.25651949625166637\t Accuracy: 0.905704365079365\n",
      "Epoch [90/500]\t Loss: 0.2554567648777886\t Accuracy: 0.9060143849206349\n",
      "Epoch [100/500]\t Loss: 0.2544427591183829\t Accuracy: 0.906312003968254\n",
      "Epoch [110/500]\t Loss: 0.2534736036308228\t Accuracy: 0.906671626984127\n",
      "Epoch [120/500]\t Loss: 0.25254586338996887\t Accuracy: 0.9070560515873016\n",
      "Epoch [130/500]\t Loss: 0.25165646445183526\t Accuracy: 0.9073040674603174\n",
      "Epoch [140/500]\t Loss: 0.25080267786979676\t Accuracy: 0.907514880952381\n",
      "Epoch [150/500]\t Loss: 0.24998203620078072\t Accuracy: 0.9078000992063492\n",
      "Epoch [160/500]\t Loss: 0.24919233265377227\t Accuracy: 0.9079737103174603\n",
      "Epoch [170/500]\t Loss: 0.24843155982948484\t Accuracy: 0.908172123015873\n",
      "Epoch [180/500]\t Loss: 0.24769791109221323\t Accuracy: 0.9083581349206349\n",
      "Epoch [190/500]\t Loss: 0.24698972626337928\t Accuracy: 0.908531746031746\n",
      "Epoch [200/500]\t Loss: 0.24630550808376736\t Accuracy: 0.9087549603174603\n",
      "Epoch [210/500]\t Loss: 0.2456438741513661\t Accuracy: 0.9090153769841269\n",
      "Epoch [220/500]\t Loss: 0.24500356250339084\t Accuracy: 0.9091765873015873\n",
      "Epoch [230/500]\t Loss: 0.24438339992175026\t Accuracy: 0.9093625992063492\n",
      "Epoch [240/500]\t Loss: 0.24378232033479783\t Accuracy: 0.9095362103174603\n",
      "Epoch [250/500]\t Loss: 0.2431993280611341\t Accuracy: 0.9098214285714286\n",
      "Epoch [260/500]\t Loss: 0.24263349629583814\t Accuracy: 0.9100198412698413\n",
      "Epoch [270/500]\t Loss: 0.24208397978828067\t Accuracy: 0.9101686507936508\n",
      "Epoch [280/500]\t Loss: 0.2415499818230432\t Accuracy: 0.910453869047619\n",
      "Epoch [290/500]\t Loss: 0.2410307612210985\t Accuracy: 0.9105282738095238\n",
      "Epoch [300/500]\t Loss: 0.24052562751467266\t Accuracy: 0.9106894841269841\n",
      "Epoch [310/500]\t Loss: 0.24003394813764664\t Accuracy: 0.9107762896825397\n",
      "Epoch [320/500]\t Loss: 0.2395551079795474\t Accuracy: 0.910999503968254\n",
      "Epoch [330/500]\t Loss: 0.2390885517710731\t Accuracy: 0.9111359126984127\n",
      "Epoch [340/500]\t Loss: 0.23863374723328484\t Accuracy: 0.9112227182539683\n",
      "Epoch [350/500]\t Loss: 0.2381901956266827\t Accuracy: 0.9113467261904762\n",
      "Epoch [360/500]\t Loss: 0.23775743402185895\t Accuracy: 0.9114955357142858\n",
      "Epoch [370/500]\t Loss: 0.23733501987797873\t Accuracy: 0.9117063492063492\n",
      "Epoch [380/500]\t Loss: 0.23692254783615233\t Accuracy: 0.9118427579365079\n",
      "Epoch [390/500]\t Loss: 0.23651961244287945\t Accuracy: 0.9119791666666667\n",
      "Epoch [400/500]\t Loss: 0.23612585673256525\t Accuracy: 0.9121775793650794\n",
      "Epoch [410/500]\t Loss: 0.2357409250641626\t Accuracy: 0.9123139880952381\n",
      "Epoch [420/500]\t Loss: 0.23536448909176722\t Accuracy: 0.9124875992063493\n",
      "Epoch [430/500]\t Loss: 0.23499623669518366\t Accuracy: 0.9126612103174603\n",
      "Epoch [440/500]\t Loss: 0.23463587623739998\t Accuracy: 0.9127480158730159\n",
      "Epoch [450/500]\t Loss: 0.234283122940669\t Accuracy: 0.9128844246031746\n",
      "Epoch [460/500]\t Loss: 0.23393770654996235\t Accuracy: 0.9129588293650793\n",
      "Epoch [470/500]\t Loss: 0.23359938178743636\t Accuracy: 0.9131200396825396\n",
      "Epoch [480/500]\t Loss: 0.23326789996926747\t Accuracy: 0.9131944444444444\n",
      "Epoch [490/500]\t Loss: 0.23294303246906825\t Accuracy: 0.9132688492063492\n",
      "Output directory already exists, will override everything there...\n",
      "\n",
      "[FINAL]\t Loss: 0.8043605439619363\t Accuracy: 0.8232146869382864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fig = plt.figure()\n",
    "acc = np.zeros(int(args.logistic_epochs/10))\n",
    "x_axe = np.linspace(0, args.logistic_epochs, int(args.logistic_epochs/10), endpoint=True)\n",
    "\n",
    "for epoch in range(args.logistic_epochs):\n",
    "    loss_epoch, accuracy_epoch = train(args, arr_train_loader, simclr_model, model, criterion, optimizer)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch [{epoch}/{args.logistic_epochs}]\\t Loss: {loss_epoch / len(train_loader_label)}\\t Accuracy: {accuracy_epoch / len(train_loader_label)}\")\n",
    "        acc[int(epoch/10)-1] = accuracy_epoch / len(train_loader_label)\n",
    "\n",
    "# final testing\n",
    "results_save_path = \"model18_simclr_20\"\n",
    "if not os.path.isdir(results_save_path):\n",
    "    os.mkdir(results_save_path)\n",
    "else:\n",
    "    print(\"Output directory already exists, will override everything there...\")\n",
    "    \n",
    "loss_epoch, accuracy_epoch = test(args, arr_test_loader, simclr_model, model, criterion, optimizer, 0.2, results_save_path)\n",
    "\n",
    "print(f\"\\n[FINAL]\\t Loss: {loss_epoch / len(test_loader)}\\t Accuracy: {accuracy_epoch / len(test_loader)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae2f05e3af815ef614f46579a3d010a9c17130217ca8692da23708d790b37f37"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
